[{"authors":null,"categories":null,"content":"I am a Ph.D. student in the department of Computer Science at the University of Maryland, College Park. I am being advised by Prof. Abhinav Shrivastava. My research interests include machine learning and computer vision. Currently, my research focuses on data compression and model compression/pruning of deep networks for a variety of vision tasks.\nI completed my Bachelor\u0026rsquo;s degree from the Department of Electrical Engineering at the Indian Institute of Technology Madras where I worked with Prof. A.N. Rajagopalan and Prof. Kaushik Mitra.\nDownload my CV.\nI am on the job market this year. Please reach out to me if I\u0026rsquo;m a good fit for your team!\n","date":1672531200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1672531200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a Ph.D. student in the department of Computer Science at the University of Maryland, College Park. I am being advised by Prof. Abhinav Shrivastava. My research interests include machine learning and computer vision.","tags":null,"title":"Sharath Girish","type":"authors"},{"authors":["Sharath Girish","Kamal Gupta","Abhinav Shrivastava"],"categories":null,"content":" ","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"3cf714bafc8b92126ac68a7056c4a329","permalink":"/publication/eagles/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/publication/eagles/","section":"publication","summary":"We introduce an end-to-end trainable compression framework for 3D Gaussian Splatting (3D-GS). We learn quantized latent representations and parameterized decoders reducing per-point memory for each Gaussian. We introduce a coarse-to-fine progressive training strategy for accelerating training while improving the optimization. We also develop a pruning stage resulting in fewer Gaussians and faster rendering speeds for 3D-GS.","tags":[],"title":"EAGLES: Efficient Accelerated 3D Gaussians with Lightweight EncodingS","type":"publication"},{"authors":["Sharath Girish","Abhinav Shrivastava","Kamal Gupta"],"categories":null,"content":" ","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"4b02ac0aef9edd510b23cb1938fdfa9d","permalink":"/publication/shacira/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/publication/shacira/","section":"publication","summary":"_International Conference on Computer Vision (ICCV), 2023_ \n\n We introduce an end-to-end trainable compression framework for implicit feature grids by maintaining discrete latent representations and parameterized decoders. The training is made differentiable with various tricks such as gumbel reparameterization. We provide extensive experiments on compression benchmarks for a variety of domains such as images, videos, and 3D scenes showing the generalizability of our approach. outperforming a variety of INR works. Our approach scales well to higher resolution data and converges faster than traditional INR approaches.","tags":[],"title":"SHACIRA: Scalable HAsh-grid Compression for Implicit Neural Representations","type":"publication"},{"authors":["Sharath Girish","Kamal Gupta","Saurabh Singh","Abhinav Shrivastava"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"618ee989f9fd3192667dfa3569b6073f","permalink":"/publication/lilnetx/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/publication/lilnetx/","section":"publication","summary":"_International Conference on Learning Representations (ICLR), 2023_ \n\n We propose an end-to-end trainable framework for simultaneously optimizing for model compression and sparsity of deep networks. We construct a joint training objective penalizing the entropy of latent representations of model weights. We introduce priors to increase the structured sparsity in the parameter space outperforming existing state-of-the-art model compression methods while also achieving inference speedups through structured sparsity.","tags":[],"title":"LilNetX: Lightweight Networks with EXtreme Model Compression and Structured Sparsification","type":"publication"},{"authors":["Shishira R Maiya*","Sharath Girish*","Max Ehrlich","Hanyu Wang","Kwot Sin Lee","Patrick Poirson","Pengxiang Wu","Chen Wang","Abhinav Shrivastava"],"categories":null,"content":" ","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"1694c54f0e1aae33a3baffb305653a5a","permalink":"/publication/nirvana/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/publication/nirvana/","section":"publication","summary":"_IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023_ \n\n We propose an implicit neural representation (INR) algorithm for videos by fitting separate networks to groups of frames while performing patch-wise prediction. This design shares computation in the spatial and temporal dimension leading to reduced encoding times. The video representation is modeled autoregressively with networks fit on a current group conditioned on the previous group's network weights. We achieve 12X speedups compared to prior video INR approaches while maintaining encoding quality and compression rate. Additionally, we adapt to video content and naturally scale to longer videos or larger frame resolution.","tags":[],"title":"NIRVANA: Neural Implicit Representations of Videos with Adaptive Networks and Autoregressive Patch-wise Modeling","type":"publication"},{"authors":["Sharath Girish","Debadeepta Dey","Neel Joshi","Vibhav Vineet","Shital Shah","Caio Cesar Teodoro Mendes","Abhinav Shrivastava","Yale Song"],"categories":null,"content":" ","date":1646092800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646092800,"objectID":"f7a706b178b2f82ac1618aef489b2e9d","permalink":"/publication/nas_ssl/","publishdate":"2022-03-01T00:00:00Z","relpermalink":"/publication/nas_ssl/","section":"publication","summary":"_Under review_ \n\n We conduct a large scale study to analyze the role of architectures in SSL with over 100 variants of ResNets/MobileNets. We show that there is no one network that performs consistently well across the scenarios. Based on this, we propose to apply NAS for SSL and show that the searched architectures outperform popular handcrafted architectures (ResNet18 and MobileNetV2) while performing competitively with the larger and computationally heavy ResNet50 on major image classification benchmarks.","tags":[],"title":"One Network Doesn't Rule Them All: Moving Beyond Handcrafted Architectures in Self-Supervised Learning","type":"publication"},{"authors":["Sharath Girish*","Shishira R Maiya*","Kamal Gupta","Hao Chen","Larry Davis","Abhinav Shrivastava"],"categories":null,"content":" ","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625097600,"objectID":"841a2cf90db5024f6df2fbce30356964","permalink":"/publication/lth/","publishdate":"2021-07-01T00:00:00Z","relpermalink":"/publication/lth/","section":"publication","summary":"_IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021_ \n\n We perform an empirical study to investigate the Lottery Ticket Hypothesis (LTH) for deep network pruning in the context of object detection, instance segmentation, and keypoint estimation. Our studies reveal that lottery tickets obtained from Imagenet pretraining do not transfer well to the downstream tasks. We provide guidance on how to find lottery tickets with up to 80% overall sparsity on different sub-tasks without incurring any drop in the performance.","tags":[],"title":"The Lottery Ticket Hypothesis for Object Recognition","type":"publication"},{"authors":["Sharath Girish*","Saksham Suri*","Saketh Rambhatla","Abhinav Shrivastava"],"categories":null,"content":" ","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633046400,"objectID":"4224617afd164f19492bdf60afe209af","permalink":"/publication/gan_discovery/","publishdate":"2021-10-01T00:00:00Z","relpermalink":"/publication/gan_discovery/","section":"publication","summary":"_IEEE International Conference on Computer Vision (ICCV), 2021_ \n\n We propose an approach for discovering and attributing images to previously unseen GAN sources by utilizing only a small labeled set of GAN generated images. Our pipeline consists of multiple stages of network training, Out-Of-Distribution (OOD) detection, and merging and refining clusters. Our approach attributes images to seen GAN sources while also discovering new sources.","tags":[],"title":"Towards Discovery and Attribution of Open-world GAN Generated Images","type":"publication"},{"authors":["M. R. Mahesh Mohan","Sharath Girish","A. N. alan"],"categories":null,"content":" ","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"08cdc9ce83deecdd54e494ab9d992f36","permalink":"/publication/dual_deblur/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/publication/dual_deblur/","section":"publication","summary":"_IEEE International Conference on Computer Vision (ICCV), 2019 (Oral)_ \n\n We propose a generalized blur model for dual-lens (DL) setups on smartphones and formulate an algorithm for blind motion deblurring (BMD) for unconstrained camera configurations. The approach employs prior enforcing scene consistent disparities which handles the ill-posedness present in DL-BMD achieving state-of-the-art results for DL setups.","tags":[],"title":"Unconstrained Motion Deblurring for Dual-lens Cameras","type":"publication"},{"authors":["Anil Kumar Vadathya","Sharath Girish","Kaushik Mitra"],"categories":null,"content":" ","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"31d3999a9f02e7000e14bbcfcd27050c","permalink":"/publication/light_fields/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/publication/light_fields/","section":"publication","summary":"_IEEE Transactions on Computational Imaging_ \n\n We propose an approach for light field (LF) reconstruction from coded images. Our algorithm consists of three stages; recovering the all-in-focus image from the coded image, estimating the disparity maps for all LF views and rendering the LF by warping the all-in-focus image with the disparity maps. We show results on three multiplexing schemes and also achieve high quality LF reconstructions with conventional cameras and no hardware modifications.","tags":[],"title":"A unified learning-based framework for light field reconstruction from coded projections","type":"publication"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Sharath Girish","吳恩達"],"categories":["Demo","教程"],"content":"Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It\u0026rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more The template is mobile first with a responsive design to ensure that your site looks stunning on every device. Get Started 👉 Create a new site 📚 Personalize your site 💬 Chat with the Wowchemy community or Hugo community 🐦 Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy 💡 Request a feature or report a bug for Wowchemy ⬆️ Updating Wowchemy? View the Update Guide and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n❤️ Click here to become a sponsor and help support Wowchemy\u0026rsquo;s future ❤️ As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features 🦄✨\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome 👋 We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","开源"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne **Two** Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}} Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]